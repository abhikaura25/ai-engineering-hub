{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000c0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START, END\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2cb9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "    review: str\n",
    "    semantic_feedback: Literal[\"positive\", \"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str\n",
    "\n",
    "class SemanticFeedback(BaseModel):\n",
    "    feedback: Literal[\"positive\", \"negative\"] = Field(..., description=\"Indicates whether the review is positive or negative.\")\n",
    "\n",
    "class Diagnosis(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')\n",
    "\n",
    "structured_output_model = model.with_structured_output(SemanticFeedback)\n",
    "structured_output_diagnosis_model = model.with_structured_output(Diagnosis)\n",
    "\n",
    "def get_semantic_feedback(state: ReviewState) -> dict:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"review\"],\n",
    "        template=\"Analyze the following review and determine if it is positive or negative:\\n\\n{review}\\n\\nRespond with 'positive' or 'negative'.\"\n",
    "    )\n",
    "    response = structured_output_model.invoke(prompt.format_prompt(review=state['review']).to_string())\n",
    "    return {'semantic_feedback': response.feedback}\n",
    "\n",
    "def get_diagnosis(state: ReviewState) -> dict:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"review\"],\n",
    "        template=\"Analyze the following review and determine the issue type, tone, and urgency:\\n\\n{review}\\n\\nRespond with a JSON object containing 'issue_type', 'tone', and 'urgency'.\"\n",
    "    )\n",
    "    response = structured_output_diagnosis_model.invoke(prompt.format_prompt(review=state['review']).to_string())\n",
    "    return {'diagnosis': {\n",
    "        \"issue_type\": response.issue_type,\n",
    "        \"tone\": response.tone,\n",
    "        \"urgency\": response.urgency\n",
    "    }}\n",
    "\n",
    "def get_positive_response(state: ReviewState) -> dict:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"review\"],\n",
    "        template=\"The following is a positive customer review:\\n\\n{review}\\n\\nWrite a short, warm thank-you response acknowledging their feedback.\"\n",
    "    )\n",
    "    response = model.invoke(prompt.format_prompt(review=state['review']).to_string())\n",
    "    return {'response': response.content}\n",
    "\n",
    "def check_sentiment(state: ReviewState) -> Literal[\"get_positive_response\", \"get_diagnosis\"]:\n",
    "    if state['semantic_feedback'] == \"positive\":\n",
    "        return \"get_positive_response\"\n",
    "    else:\n",
    "        return \"get_diagnosis\"\n",
    "    \n",
    "\n",
    "def get_negative_response(state: ReviewState):\n",
    "\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e27c573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': 'The product quality is outstanding and exceeded my expectations!', 'semantic_feedback': 'positive', 'response': \"Dear [Customer's Name],\\n\\nThank you so much for your kind words! We're thrilled to hear that the product exceeded your expectations. Your satisfaction means the world to us! If you have any more feedback or need assistance, please don't hesitate to reach out.\\n\\nWarm regards,  \\n[Your Name]  \\n[Your Company]  \"}\n"
     ]
    }
   ],
   "source": [
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node(\"get_semantic_feedback\", get_semantic_feedback)\n",
    "graph.add_node(\"get_diagnosis\", get_diagnosis)\n",
    "graph.add_node(\"get_positive_response\", get_positive_response)\n",
    "graph.add_node(\"get_negative_response\", get_negative_response)\n",
    "\n",
    "graph.add_edge(START, \"get_semantic_feedback\")\n",
    "graph.add_conditional_edges(\"get_semantic_feedback\", check_sentiment)\n",
    "graph.add_edge(\"get_positive_response\", END)\n",
    "graph.add_edge(\"get_diagnosis\", \"get_negative_response\")\n",
    "graph.add_edge(\"get_negative_response\", END)\n",
    "\n",
    "compiled_graph = graph.compile()\n",
    "\n",
    "result = compiled_graph.invoke({\n",
    "    \"review\": \"The product quality is outstanding and exceeded my expectations!\"\n",
    "})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
